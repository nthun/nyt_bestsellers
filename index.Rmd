---
title: "NYT Bestsellers anlaysis"
output: html_document
date: '2022-05-11'
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggrepel)

theme_set(theme_light())
```

We will analyze the NYT bestseller data and see which books were the most popular.


```{r}
nyt_titles <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_titles.tsv')

nyt_full <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_full.tsv')


```


```{r}
nyt <-
  nyt_titles %>% 
  mutate(title = str_to_title(title),
         total_years = total_weeks/52,
         decade = floor(year/10)*10)

```


# Books with longest ranking time

```{r}

nyt_titles %>% 
  arrange(desc(total_weeks)) %>% 
  slice(1:20) %>% 
  ggplot() +
  aes(x = year, y = total_weeks, label = title) +
  geom_point() +
  geom_text_repel()
  
  
```

# Make a plot that shows the number of weeks spent on BS list 

```{r}
nyt %>% 
  slice_max(total_weeks, n = 30) %>%
  mutate(title = fct_reorder(title, year)) %>% 
  ggplot() +
  aes(xmin = year, xmax = year + total_years, y = title) +
  geom_linerange(size = 1.5) +
  labs(y = NULL)
  
  
```

# Which decade had books that were on the bestseller list for the longest time?

```{r}
top3 <- 
  nyt %>% 
  group_by(decade) %>% 
  slice_max(total_weeks, n = 3) %>% 
  arrange(-total_weeks) %>% 
  mutate(rank = row_number()) %>% 
  ungroup()

nyt %>% 
  group_by(decade) %>% 
  summarise(avg_time_onlist = mean(total_weeks)) %>% 
  ggplot() +
  aes(x = decade, y = avg_time_onlist) +
  geom_line() +
  geom_point() +
  labs(title = "Average time on NYT bestseller list by decade", 
       subtitle = "The 1960-1970's books were on the bestseller list for the longest time",
       y = "Average time on NYT bestseller list",
       x = NULL)

```

# 3 most successful books of each decade
```{r}

top3 %>% 
  ggplot() +
  aes(x = year, y = total_weeks, label = title) +
  # geom_tile(aes(x = decade, y = Inf)) +
  geom_col(position = "dodge") +
  geom_text_repel() +
  scale_x_continuous(breaks = seq(1930, 2020, 10)) +
  labs(x = NULL, y = "Total weeks on bestseller list")

```



# The number of books on list from the full datasets
There may be a bias that comes from the number of books that were selected to the smaller dataset.

```{r}

nyt_full %>% 
  count(year) %>% 
  ggplot() +
  aes(x = year, y = n) +
  geom_line() +
  geom_point() + 
  labs(title = "Number of books by year from the full dataset")

nyt_full %>% 
  mutate(decade = floor(year/10)*10) %>% 
  count(decade) %>% 
  ggplot() +
  aes(x = decade, y = n) +
  geom_line() +
  geom_point() + 
  labs(title = "Number of books by year from the full dataset")

```

```{r}
# imdb_raw <- read_tsv("title.basics.tsv/data.tsv")
# 
# distinct(imdb_raw, titleType)
# 
# imdb <- 
#   imdb_raw %>% 
#   transmute(title = str_to_title(primaryTitle),
#             year_movie = startYear,
#             runtime = runtimeMinutes,
#             genres,
#             titleType,
#             adaptation = 1) %>% 
#   filter(titleType == "movie")
# 
# 
# adaptations <-
#   nyt %>% 
#   left_join(imdb, by = "title")

```



